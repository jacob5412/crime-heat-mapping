{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import logging\n",
    "import data_helper\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from text_cnn_rnn import TextCNNRNN\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_params(trained_dir):\n",
    "\tparams = json.loads(open(trained_dir + 'trained_parameters.json').read())\n",
    "\twords_index = json.loads(open(trained_dir + 'words_index.json').read())\n",
    "\tlabels = json.loads(open(trained_dir + 'labels.json').read())\n",
    "\n",
    "\twith open(trained_dir + 'embeddings.pickle', 'rb') as input_file:\n",
    "\t\tfetched_embedding = pickle.load(input_file)\n",
    "\tembedding_mat = np.array(fetched_embedding, dtype = np.float32)\n",
    "\treturn params, words_index, labels, embedding_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(test_file, labels):\n",
    "\tdf = pd.read_csv(test_file, sep='|')\n",
    "\tselect = ['Descript']\n",
    "\n",
    "\tdf = df.dropna(axis=0, how='any', subset=select)\n",
    "\ttest_examples = df[select[0]].apply(lambda x: data_helper.clean_str(x).split(' ')).tolist()\n",
    "\n",
    "\tnum_labels = len(labels)\n",
    "\tone_hot = np.zeros((num_labels, num_labels), int)\n",
    "\tnp.fill_diagonal(one_hot, 1)\n",
    "\tlabel_dict = dict(zip(labels, one_hot))\n",
    "\n",
    "\ty_ = None\n",
    "\tif 'Category' in df.columns:\n",
    "\t\tselect.append('Category')\n",
    "\t\ty_ = df[select[1]].apply(lambda x: label_dict[x]).tolist()\n",
    "\n",
    "\tnot_select = list(set(df.columns) - set(select))\n",
    "\tdf = df.drop(not_select, axis=1)\n",
    "\treturn test_examples, y_, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_word_to_index(examples, words_index):\n",
    "\tx_ = []\n",
    "\tfor example in examples:\n",
    "\t\ttemp = []\n",
    "\t\tfor word in example:\n",
    "\t\t\tif word in words_index:\n",
    "\t\t\t\ttemp.append(words_index[word])\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp.append(0)\n",
    "\t\tx_.append(temp)\n",
    "\treturn x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unseen_data(train, test):\n",
    "\ttrained_dir = train\n",
    "\tif not trained_dir.endswith('/'):\n",
    "\t\ttrained_dir += '/'\n",
    "\ttest_file = test\n",
    "\n",
    "\tparams, words_index, labels, embedding_mat = load_trained_params(trained_dir)\n",
    "\tx_, y_, df = load_test_data(test_file, labels)\n",
    "\tx_ = data_helper.pad_sentences(x_, forced_sequence_length=params['sequence_length'])\n",
    "\tx_ = map_word_to_index(x_, words_index)\n",
    "\n",
    "\tx_test, y_test = np.asarray(x_), None\n",
    "\tif y_ is not None:\n",
    "\t\ty_test = np.asarray(y_)\n",
    "\n",
    "\ttimestamp = trained_dir.split('/')[-2].split('_')[-1]\n",
    "\tpredicted_dir = './predicted_sentence_' + timestamp + '/'\n",
    "\tif os.path.exists(predicted_dir):\n",
    "\t\tshutil.rmtree(predicted_dir)\n",
    "\tos.makedirs(predicted_dir)\n",
    "\n",
    "\twith tf.Graph().as_default():\n",
    "\t\tsession_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "\t\tsess = tf.Session(config=session_conf)\n",
    "\t\twith sess.as_default():\n",
    "\t\t\tcnn_rnn = TextCNNRNN(\n",
    "\t\t\t\tembedding_mat = embedding_mat,\n",
    "\t\t\t\tnon_static = params['non_static'],\n",
    "\t\t\t\thidden_unit = params['hidden_unit'],\n",
    "\t\t\t\tsequence_length = len(x_test[0]),\n",
    "\t\t\t\tmax_pool_size = params['max_pool_size'],\n",
    "\t\t\t\tfilter_sizes = map(int, params['filter_sizes'].split(\",\")),\n",
    "\t\t\t\tnum_filters = params['num_filters'],\n",
    "\t\t\t\tnum_classes = len(labels),\n",
    "\t\t\t\tembedding_size = params['embedding_dim'],\n",
    "\t\t\t\tl2_reg_lambda = params['l2_reg_lambda'])\n",
    "\n",
    "\t\t\tdef real_len(batches):\n",
    "\t\t\t\treturn [np.ceil(np.argmin(batch + [0]) * 1.0 / params['max_pool_size']) for batch in batches]\n",
    "\n",
    "\t\t\tdef predict_step(x_batch):\n",
    "\t\t\t\tfeed_dict = {\n",
    "\t\t\t\t\tcnn_rnn.input_x: x_batch,\n",
    "\t\t\t\t\tcnn_rnn.dropout_keep_prob: 1.0,\n",
    "\t\t\t\t\tcnn_rnn.batch_size: len(x_batch),\n",
    "\t\t\t\t\tcnn_rnn.pad: np.zeros([len(x_batch), 1, params['embedding_dim'], 1]),\n",
    "\t\t\t\t\tcnn_rnn.real_len: real_len(x_batch),\n",
    "\t\t\t\t}\n",
    "\t\t\t\tpredictions = sess.run([cnn_rnn.predictions], feed_dict)\n",
    "\t\t\t\treturn predictions\n",
    "\n",
    "\t\t\tcheckpoint_file = trained_dir + 'best_model.ckpt'\n",
    "\t\t\tsaver = tf.train.Saver(tf.all_variables())\n",
    "\t\t\tsaver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "\t\t\tsaver.restore(sess, checkpoint_file)\n",
    "\t\t\tlogging.critical('{} has been loaded'.format(checkpoint_file))\n",
    "\n",
    "\t\t\tbatches = data_helper.batch_iter(list(x_test), params['batch_size'], 1, shuffle=False)\n",
    "\n",
    "\t\t\tpredictions, predict_labels = [], []\n",
    "\t\t\tfor x_batch in batches:\n",
    "\t\t\t\tbatch_predictions = predict_step(x_batch)[0]\n",
    "\t\t\t\tfor batch_prediction in batch_predictions:\n",
    "\t\t\t\t\tpredictions.append(batch_prediction)\n",
    "\t\t\t\t\tpredict_labels.append(labels[batch_prediction])\n",
    "\n",
    "\t\t\t# Save the predictions back to file\n",
    "\t\t\tdf['NEW_PREDICTED'] = predict_labels\n",
    "\t\t\tcolumns = sorted(df.columns, reverse=True)\n",
    "\t\t\tdf.to_csv(predicted_dir + 'predictions_all.csv', index=False, columns=columns, sep='|')\n",
    "\n",
    "\t\t\tif y_test is not None:\n",
    "\t\t\t\ty_test = np.array(np.argmax(y_test, axis=1))\n",
    "\t\t\t\taccuracy = sum(np.array(predictions) == y_test) / float(len(y_test))\n",
    "\t\t\t\tlogging.critical('The prediction accuracy is: {}'.format(accuracy))\n",
    "\n",
    "\t\t\tlogging.critical('Prediction is complete, all files have been saved: {}'.format(predicted_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E1104 14:44:29.382025 4603076032 data_helper.py:45] CRITICAL - This is prediction, reading the trained sequence length\n",
      "E1104 14:44:29.383793 4603076032 data_helper.py:47] CRITICAL - The maximum length is 14\n",
      "W1104 14:44:29.391773 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:11: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1104 14:44:29.445757 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:42: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1104 14:44:29.475862 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:49: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1104 14:44:29.597176 4603076032 deprecation.py:506] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1104 14:44:29.618608 4603076032 deprecation.py:323] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:59: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1104 14:44:29.661957 4603076032 deprecation.py:323] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W1104 14:44:29.706131 4603076032 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1104 14:44:29.718244 4603076032 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1104 14:44:29.768776 4603076032 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1104 14:44:30.031239 4603076032 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1104 14:44:30.364732 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:73: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1104 14:44:30.365988 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:74: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1104 14:44:30.370635 4603076032 deprecation.py:323] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:78: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1104 14:44:30.454146 4603076032 deprecation_wrapper.py:119] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:88: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "W1104 14:44:30.464545 4603076032 deprecation.py:323] From /Users/jacobjohn/Codes/crime-heat-mapping/multi-class-text-classification-cnn-rnn/text_cnn_rnn.py:92: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W1104 14:44:30.518204 4603076032 deprecation.py:323] From <ipython-input-5-454578bf0952>:53: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W1104 14:44:31.136422 4603076032 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I1104 14:44:31.138463 4603076032 saver.py:1280] Restoring parameters from ./trained_results_1572842981/best_model.ckpt\n",
      "E1104 14:44:31.284780 4603076032 <ipython-input-5-454578bf0952>:56] CRITICAL - ./trained_results_1572842981/best_model.ckpt has been loaded\n",
      "E1104 14:44:31.548907 4603076032 <ipython-input-5-454578bf0952>:75] CRITICAL - The prediction accuracy is: 1.0\n",
      "E1104 14:44:31.549758 4603076032 <ipython-input-5-454578bf0952>:77] CRITICAL - Prediction is complete, all files have been saved: ./predicted_sentence_1572842981/\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "predict_unseen_data(train = './trained_results_1572842981/', test = './data/sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
